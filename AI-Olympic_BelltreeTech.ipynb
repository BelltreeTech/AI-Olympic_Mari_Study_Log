{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4420a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ã€è¨­å®šã€‘ train.csvã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆé©å®œæ›¸ãæ›ãˆã‚‹ã“ã¨ï¼‰\n",
    "FILE_PATH = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv\"\n",
    "\n",
    "\n",
    "def inspect_data():\n",
    "    print(\"Loading data... (This might take a while)\")\n",
    "    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚€ã¨é‡ã„å ´åˆãŒã‚ã‚‹ã®ã§ã€æœ€åˆã®10ä¸‡è¡Œã ã‘èª­ã‚€æ‰‹ã‚‚ã‚ã‚‹ãŒã€ä¸€æ—¦å…¨éƒ¨èª­ã‚€\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "    print(\"\\nData Overview:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # è„³æ´»å‹•ã®ã‚«ãƒ©ãƒ ã‚’ç‰¹å®šï¼ˆ'AUD'ãªã©ã§å§‹ã¾ã‚‹ã‚«ãƒ©ãƒ ã¨ä»®å®šï¼‰\n",
    "    # Overviewã«ã‚ˆã‚‹ã¨ã€AUDp_l, AUDs_l ... VISrl_r ã¨ã„ã£ãŸåå‰ã‚‰ã—ã„\n",
    "    # é™¤å¤–ã‚«ãƒ©ãƒ : id, sample_id, mouse_id, day_n, time, lever\n",
    "    exclude_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "    brain_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "    print(f\"\\nBrain Activity Columns detected: {len(brain_cols)} columns\")\n",
    "    print(f\"Examples: {brain_cols[:5]} ...\")\n",
    "\n",
    "    # --- å¯è¦–åŒ–: ãƒ©ãƒ³ãƒ€ãƒ ãª1ã¤ã®sample_idã‚’é¸ã‚“ã§ãƒ—ãƒ­ãƒƒãƒˆ ---\n",
    "    unique_samples = df[\"sample_id\"].unique()\n",
    "    target_sample = unique_samples[0]  # ã¨ã‚Šã‚ãˆãšæœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã‚‹\n",
    "\n",
    "    sample_data = df[df[\"sample_id\"] == target_sample]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # å·¦è»¸: è„³æ´»å‹•ï¼ˆå…¨éƒ¨æãã¨è¦‹ã«ãã„ã®ã§ã€æœ€åˆã®5ã¤ã ã‘æç”»ï¼‰\n",
    "    # ã‚‚ã—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãŒè¦‹ãŸã‘ã‚Œã°ã€sns.heatmapã‚’ä½¿ã†æ‰‹ã‚‚ã‚ã‚‹\n",
    "    for col in brain_cols[:5]:\n",
    "        ax1.plot(\n",
    "            sample_data[\"time\"], sample_data[col], alpha=0.5, label=f\"Brain: {col}\"\n",
    "        )\n",
    "\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "    ax1.set_ylabel(\"Brain Activity (Fluorescence)\", color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # å³è»¸: ãƒ¬ãƒãƒ¼ä½ç½® (Target)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        sample_data[\"time\"],\n",
    "        sample_data[\"lever\"],\n",
    "        color=\"red\",\n",
    "        linewidth=2,\n",
    "        linestyle=\"--\",\n",
    "        label=\"Target: Lever\",\n",
    "    )\n",
    "    ax2.set_ylabel(\"Lever Position\", color=\"red\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    plt.title(f\"Brain Activity vs Lever Position (Sample ID: {target_sample})\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- ç›¸é–¢è¡Œåˆ— (Heatmap) ---\n",
    "    # ãƒ¬ãƒãƒ¼ã¨å„è„³é ˜åŸŸã®ç›¸é–¢ã‚’è¦‹ã‚‹\n",
    "    print(\"\\nCalculating correlation with Lever...\")\n",
    "    correlations = (\n",
    "        df[brain_cols + [\"lever\"]].corr()[\"lever\"].sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # ãƒ¬ãƒãƒ¼ã¨ç›¸é–¢ãŒé«˜ã„ä¸Šä½10å€‹ã¨ä¸‹ä½10å€‹ã‚’è¡¨ç¤º\n",
    "    top_corr = correlations.head(11)  # leverè‡ªèº«å«ã‚€\n",
    "    sns.barplot(x=top_corr.values, y=top_corr.index)\n",
    "    plt.title(\"Top Brain Regions correlated with Lever\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (223832, 264)\n",
      "Training set:   (179065, 264)\n",
      "Validation set: (44767, 264)  <-- This is the Truth.\n",
      "Start Training (Hidden=512)... Watch Validation Loss!\n",
      "Iter 0 | Train: 1.0185 | Val: 1.0690\n",
      "Iter 200 | Train: 0.7144 | Val: 0.6517\n",
      "Iter 400 | Train: 0.5804 | Val: 0.6366\n",
      "Iter 600 | Train: 0.5809 | Val: 0.5914\n",
      "Iter 800 | Train: 0.5427 | Val: 0.5926\n",
      "Iter 1000 | Train: 0.5283 | Val: 0.5847\n",
      "Iter 1200 | Train: 0.6818 | Val: 0.5927\n",
      "Iter 1400 | Train: 0.5666 | Val: 0.5715\n",
      "Iter 1600 | Train: 0.4999 | Val: 0.5610\n",
      "Iter 1800 | Train: 0.5563 | Val: 0.5615\n",
      "Iter 2000 | Train: 0.5541 | Val: 0.5934\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ğŸ› ï¸ Operation \"Watchtower\" - Validation & Early Stopping\n",
    "# =========================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  # â˜…ã“ã‚Œã‚’ä½¿ã†è¨±å¯ã¯å‡ºã¦ã„ã‚‹\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ãƒ©ã‚°ç‰¹å¾´é‡ (å‰å›ã¨åŒã˜)\n",
    "# ---------------------------------------------------------\n",
    "train_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv\"\n",
    "test_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/test.csv\"\n",
    "sub_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sub_path)\n",
    "\n",
    "\n",
    "# ãƒ©ã‚°ç‰¹å¾´é‡ä½œæˆ (Lag=5)\n",
    "def add_lag_features(df, lag_counts=5):\n",
    "    df_lagged = df.copy()\n",
    "    exclude_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "    brain_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "    for i in range(1, lag_counts + 1):\n",
    "        shifted = df[brain_cols].shift(i)\n",
    "        shifted.columns = [f\"{c}_lag{i}\" for c in brain_cols]\n",
    "        df_lagged = pd.concat([df_lagged, shifted], axis=1)\n",
    "    return df_lagged.fillna(0)\n",
    "\n",
    "\n",
    "print(f\"Original Train Shape: {X_train.shape}\")\n",
    "\n",
    "# â˜…é‡è¦â˜… ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œå­¦ç¿’ç”¨(80%)ã€ã¨ã€Œæ¤œè¨¼ç”¨(20%)ã€ã«åˆ†å‰²\n",
    "# shuffle=True ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ··ãœã‚‹\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {X_tr.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}  <-- This is the Truth.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ãƒ¢ãƒ‡ãƒ«å®šç¾© (åŸºæœ¬ã¯åŒã˜ã ãŒã€å°‘ã—æ”¹è‰¯)\n",
    "# ---------------------------------------------------------\n",
    "class MomentumMLP:\n",
    "    def __init__(\n",
    "        self, input_size, hidden_size, output_size, learning_rate=0.01, momentum=0.9\n",
    "    ):\n",
    "        self.params = {}\n",
    "        # He Init\n",
    "        self.params[\"W1\"] = np.random.randn(input_size, hidden_size) * np.sqrt(\n",
    "            2.0 / input_size\n",
    "        )\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"W2\"] = np.random.randn(hidden_size, output_size) * np.sqrt(\n",
    "            2.0 / hidden_size\n",
    "        )\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "\n",
    "        self.v = {}\n",
    "        for key in self.params.keys():\n",
    "            self.v[key] = np.zeros_like(self.params[key])\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def predict(self, x):\n",
    "        a1 = np.dot(x, self.params[\"W1\"]) + self.params[\"b1\"]\n",
    "        z1 = np.maximum(0, a1)\n",
    "        a2 = np.dot(z1, self.params[\"W2\"]) + self.params[\"b2\"]\n",
    "        return a2\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return 0.5 * np.mean((y - t) ** 2)\n",
    "\n",
    "    # gradient, updateã¯å‰å›ã¨åŒã˜ãªã®ã§çœç•¥ï¼ˆãã®ã¾ã¾ä½¿ã†ã“ã¨ï¼‰\n",
    "    def gradient(self, x, t):\n",
    "        grads = {}\n",
    "        batch_num = x.shape[0]\n",
    "        W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n",
    "        a1 = np.dot(x, W1) + self.params[\"b1\"]\n",
    "        z1 = np.maximum(0, a1)\n",
    "        y = np.dot(z1, W2) + self.params[\"b2\"]\n",
    "\n",
    "        dy = (y - t) / batch_num\n",
    "        grads[\"W2\"] = np.dot(z1.T, dy)\n",
    "        grads[\"b2\"] = np.sum(dy, axis=0)\n",
    "        dz1 = np.dot(dy, W2.T)\n",
    "        da1 = dz1 * (a1 > 0)\n",
    "        grads[\"W1\"] = np.dot(x.T, da1)\n",
    "        grads[\"b1\"] = np.sum(da1, axis=0)\n",
    "        return grads\n",
    "\n",
    "    def update(self, x, t):\n",
    "        grads = self.gradient(x, t)\n",
    "        for key in self.params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            self.params[key] += self.v[key]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. å­¦ç¿’å®Ÿè¡Œ (ç›£è¦–ä»˜ã)\n",
    "# ---------------------------------------------------------\n",
    "input_size = X_tr.shape[1]\n",
    "hidden_size = 512  # å°‘ã—æ¸›ã‚‰ã™ï¼ˆ1024ã¯éå­¦ç¿’ã—ã™ãã‹ã‚‚ï¼‰\n",
    "output_size = 1\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "model = MomentumMLP(input_size, hidden_size, output_size, learning_rate, momentum)\n",
    "\n",
    "iters_num = 5000\n",
    "batch_size = 512\n",
    "train_size = X_tr.shape[0]\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []  # â˜…æ¤œè¨¼ç”¨ã‚¹ã‚³ã‚¢ã®è¨˜éŒ²\n",
    "\n",
    "print(f\"Start Training (Hidden={hidden_size})... Watch Validation Loss!\")\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒŸãƒ‹ãƒãƒƒãƒ\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = X_tr[batch_mask]\n",
    "    t_batch = y_tr[batch_mask]\n",
    "\n",
    "    model.update(x_batch, t_batch)\n",
    "\n",
    "    # è¨˜éŒ² (200å›ã«1å›)\n",
    "    if i % 200 == 0:\n",
    "        # Train Loss (ä»Šã®ãƒŸãƒ‹ãƒãƒƒãƒ)\n",
    "        loss_tr = model.loss(x_batch, t_batch)\n",
    "\n",
    "        # â˜…Validation Loss (æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å…¨éƒ¨ã§æ¸¬ã‚‹)\n",
    "        # â€»é‡ã„å ´åˆã¯ä¸€éƒ¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã‚‚ã„ã„ãŒã€ä»Šå›ã¯RTX3070ã®åŠ›ã‚’ä¿¡ã˜ã¦å…¨éƒ¨ã‚„ã‚‹\n",
    "        loss_val = model.loss(X_val, y_val)\n",
    "\n",
    "        train_loss_list.append(loss_tr)\n",
    "        val_loss_list.append(loss_val)\n",
    "\n",
    "        print(f\"Iter {i} | Train: {loss_tr:.4f} | Val: {loss_val:.4f}\")\n",
    "\n",
    "    # Decay\n",
    "    if i > 0 and i % 1500 == 0:\n",
    "        model.lr *= 0.5\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. å¯è¦–åŒ– (çœŸå®Ÿã®ã‚°ãƒ©ãƒ•)\n",
    "# ---------------------------------------------------------\n",
    "plt.plot(train_loss_list, label=\"Train Loss (Memory)\")\n",
    "plt.plot(\n",
    "    val_loss_list, label=\"Val Loss (Reality)\", linewidth=2, color=\"red\"\n",
    ")  # â˜…ã“ã‚Œã‚’è¦‹ã‚ï¼\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.xlabel(\"Iterations (x200)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# äºˆæ¸¬ã¨æå‡º\n",
    "# æœ¬å½“ã¯ã€ŒVal LossãŒä¸€ç•ªä½ã‹ã£ãŸæ™‚ã®ãƒ¢ãƒ‡ãƒ«ã€ã‚’ä½¿ã†ã®ãŒãƒ™ã‚¹ãƒˆã ãŒã€\n",
    "# ã¾ãšã¯ç¾çŠ¶ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã ã€‚\n",
    "y_pred = model.predict(X_test)\n",
    "sample_sub[\"lever\"] = y_pred\n",
    "sample_sub.to_csv(\"submission_watchtower.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c20b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
