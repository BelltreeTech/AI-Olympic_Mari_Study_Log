{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4420a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... (This might take a while)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[43minspect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m, in \u001b[0;36minspect_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data... (This might take a while)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚€ã¨é‡ã„å ´åˆãŒã‚ã‚‹ã®ã§ã€æœ€åˆã®10ä¸‡è¡Œã ã‘èª­ã‚€æ‰‹ã‚‚ã‚ã‚‹ãŒã€ä¸€æ—¦å…¨éƒ¨èª­ã‚€\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData Overview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[1;32mc:\\Users\\star1\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\star1\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\star1\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\star1\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\star1\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ã€è¨­å®šã€‘ train.csvã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆé©å®œæ›¸ãæ›ãˆã‚‹ã“ã¨ï¼‰\n",
    "FILE_PATH = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv\"\n",
    "\n",
    "\n",
    "def inspect_data():\n",
    "    print(\"Loading data... (This might take a while)\")\n",
    "    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚€ã¨é‡ã„å ´åˆãŒã‚ã‚‹ã®ã§ã€æœ€åˆã®10ä¸‡è¡Œã ã‘èª­ã‚€æ‰‹ã‚‚ã‚ã‚‹ãŒã€ä¸€æ—¦å…¨éƒ¨èª­ã‚€\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "    print(\"\\nData Overview:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # è„³æ´»å‹•ã®ã‚«ãƒ©ãƒ ã‚’ç‰¹å®šï¼ˆ'AUD'ãªã©ã§å§‹ã¾ã‚‹ã‚«ãƒ©ãƒ ã¨ä»®å®šï¼‰\n",
    "    # Overviewã«ã‚ˆã‚‹ã¨ã€AUDp_l, AUDs_l ... VISrl_r ã¨ã„ã£ãŸåå‰ã‚‰ã—ã„\n",
    "    # é™¤å¤–ã‚«ãƒ©ãƒ : id, sample_id, mouse_id, day_n, time, lever\n",
    "    exclude_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "    brain_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "    print(f\"\\nBrain Activity Columns detected: {len(brain_cols)} columns\")\n",
    "    print(f\"Examples: {brain_cols[:5]} ...\")\n",
    "\n",
    "    # --- å¯è¦–åŒ–: ãƒ©ãƒ³ãƒ€ãƒ ãª1ã¤ã®sample_idã‚’é¸ã‚“ã§ãƒ—ãƒ­ãƒƒãƒˆ ---\n",
    "    unique_samples = df[\"sample_id\"].unique()\n",
    "    target_sample = unique_samples[0]  # ã¨ã‚Šã‚ãˆãšæœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã‚‹\n",
    "\n",
    "    sample_data = df[df[\"sample_id\"] == target_sample]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # å·¦è»¸: è„³æ´»å‹•ï¼ˆå…¨éƒ¨æãã¨è¦‹ã«ãã„ã®ã§ã€æœ€åˆã®5ã¤ã ã‘æç”»ï¼‰\n",
    "    # ã‚‚ã—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãŒè¦‹ãŸã‘ã‚Œã°ã€sns.heatmapã‚’ä½¿ã†æ‰‹ã‚‚ã‚ã‚‹\n",
    "    for col in brain_cols[:5]:\n",
    "        ax1.plot(\n",
    "            sample_data[\"time\"], sample_data[col], alpha=0.5, label=f\"Brain: {col}\"\n",
    "        )\n",
    "\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "    ax1.set_ylabel(\"Brain Activity (Fluorescence)\", color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # å³è»¸: ãƒ¬ãƒãƒ¼ä½ç½® (Target)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        sample_data[\"time\"],\n",
    "        sample_data[\"lever\"],\n",
    "        color=\"red\",\n",
    "        linewidth=2,\n",
    "        linestyle=\"--\",\n",
    "        label=\"Target: Lever\",\n",
    "    )\n",
    "    ax2.set_ylabel(\"Lever Position\", color=\"red\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    plt.title(f\"Brain Activity vs Lever Position (Sample ID: {target_sample})\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- ç›¸é–¢è¡Œåˆ— (Heatmap) ---\n",
    "    # ãƒ¬ãƒãƒ¼ã¨å„è„³é ˜åŸŸã®ç›¸é–¢ã‚’è¦‹ã‚‹\n",
    "    print(\"\\nCalculating correlation with Lever...\")\n",
    "    correlations = (\n",
    "        df[brain_cols + [\"lever\"]].corr()[\"lever\"].sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # ãƒ¬ãƒãƒ¼ã¨ç›¸é–¢ãŒé«˜ã„ä¸Šä½10å€‹ã¨ä¸‹ä½10å€‹ã‚’è¡¨ç¤º\n",
    "    top_corr = correlations.head(11)  # leverè‡ªèº«å«ã‚€\n",
    "    sns.barplot(x=top_corr.values, y=top_corr.index)\n",
    "    plt.title(\"Top Brain Regions correlated with Lever\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Powered by: cuda\n",
      "ğŸ”„ Reloading Data from CSV...\n",
      "ğŸ“Š Data Stats | Mean: -0.0000, Std: 1.0000\n",
      "Input Shape: (178959, 264)\n",
      "ğŸš€ Seed 42 Start...\n",
      "   Epoch 10 | Val: 1.2333\n",
      "   Epoch 20 | Val: 1.2368\n",
      "   Epoch 30 | Val: 1.2019\n",
      "   Epoch 40 | Val: 1.1901\n",
      "   Epoch 50 | Val: 1.1878\n",
      "ğŸš€ Seed 2026 Start...\n",
      "   Epoch 10 | Val: 1.2345\n",
      "   Epoch 20 | Val: 1.1985\n",
      "   Epoch 30 | Val: 1.1890\n",
      "   Epoch 40 | Val: 1.1878\n",
      "   Epoch 50 | Val: 1.1730\n",
      "ğŸš€ Seed 777 Start...\n",
      "   Epoch 10 | Val: 1.2337\n",
      "   Epoch 20 | Val: 1.2083\n",
      "   Epoch 30 | Val: 1.1964\n",
      "   Epoch 40 | Val: 1.2227\n",
      "   Epoch 50 | Val: 1.1877\n",
      "\n",
      "ğŸ† Final Average Val Loss: 1.1787\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ğŸ› ï¸ Operation \"Fresh Start\" - Annotated Version\n",
    "# =========================================================\n",
    "\n",
    "# æ•°å€¤è¨ˆç®—ã®åŸºç¤ï¼ˆè¡Œåˆ—è¨ˆç®—ãªã©ï¼‰\n",
    "import numpy as np\n",
    "\n",
    "# è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®æ“ä½œ\n",
    "import pandas as pd\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•æç”»ï¼ˆä»Šå›ã¯ä½¿ã£ã¦ã„ãªã„ãŒæ…£ç¿’ã¨ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PyTorchè»å›£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---\n",
    "import torch\n",
    "import torch.nn as nn  # Neural Network: å±¤ï¼ˆLinear, ReLUãªã©ï¼‰ã®éƒ¨å“ç®±\n",
    "import torch.optim as optim  # Optimizer: æœ€é©åŒ–æ‰‹æ³•ï¼ˆSGD, Adamãªã©ï¼‰ã®éƒ¨å“ç®±\n",
    "from torch.utils.data import DataLoader, TensorDataset  # ãƒ‡ãƒ¼ã‚¿ä¾›çµ¦ä¿‚\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "# ---------------------------------------------------------\n",
    "# GPU(cuda)ãŒä½¿ãˆã‚‹ã‹ç¢ºèªã€‚ä½¿ãˆãªã‘ã‚Œã°CPUã€‚\n",
    "# ã“ã‚ŒãŒã€Œä½œæ¥­ç¾å ´ã€ã‚’æ±ºã‚ã‚‹ã€‚GPUãªã‚‰å·¥å ´ã€CPUãªã‚‰é›»å“ã€‚\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ”¥ Powered by: {device}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™ (ã“ã“ã¯Pandas/NumPyã®ä¸–ç•Œ)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ğŸ”„ Reloading Data from CSV...\")\n",
    "train_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv\"\n",
    "test_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/test.csv\"\n",
    "sub_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sub_path)\n",
    "\n",
    "\n",
    "# ãƒ©ã‚°ç‰¹å¾´é‡ä½œæˆ (NumPyç‰ˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)\n",
    "def add_lag_features(df, lag_counts=5):\n",
    "    df_lagged = df.copy()\n",
    "    exclude_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "    brain_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "    for i in range(1, lag_counts + 1):\n",
    "        shifted = df[brain_cols].shift(i)\n",
    "        shifted.columns = [f\"{c}_lag{i}\" for c in brain_cols]\n",
    "        df_lagged = pd.concat([df_lagged, shifted], axis=1)\n",
    "    return df_lagged.fillna(0)\n",
    "\n",
    "\n",
    "train_df = add_lag_features(train_df, lag_counts=5)\n",
    "test_df = add_lag_features(test_df, lag_counts=5)\n",
    "\n",
    "# ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰² (Leakageé˜²æ­¢)\n",
    "unique_ids = train_df[\"sample_id\"].unique()\n",
    "np.random.seed(42)\n",
    "shuffled_ids = np.random.permutation(unique_ids)\n",
    "split_point = int(len(shuffled_ids) * 0.8)\n",
    "train_ids = shuffled_ids[:split_point]\n",
    "val_ids = shuffled_ids[split_point:]\n",
    "\n",
    "tr_df = train_df[train_df[\"sample_id\"].isin(train_ids)]\n",
    "val_df = train_df[train_df[\"sample_id\"].isin(val_ids)]\n",
    "\n",
    "# æ­£è¦åŒ–ã®ãŸã‚ã®æº–å‚™\n",
    "metadata_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "target_col = \"lever\"\n",
    "feature_cols = [\n",
    "    c\n",
    "    for c in train_df.columns\n",
    "    if c not in metadata_cols and c != target_col and \"Unnamed\" not in c\n",
    "]\n",
    "\n",
    "# Pandas -> NumPyå¤‰æ› (.values)\n",
    "X_tr_raw = tr_df[feature_cols].values\n",
    "y_tr = tr_df[target_col].values.reshape(-1, 1)\n",
    "X_val_raw = val_df[feature_cols].values\n",
    "y_val = val_df[target_col].values.reshape(-1, 1)\n",
    "X_test_raw = test_df[feature_cols].values\n",
    "\n",
    "# æ­£è¦åŒ– (Mean=0, Std=1)\n",
    "mean = X_tr_raw.mean(axis=0)\n",
    "std = X_tr_raw.std(axis=0) + 1e-8\n",
    "X_tr = (X_tr_raw - mean) / std\n",
    "X_val = (X_val_raw - mean) / std\n",
    "X_test = (X_test_raw - mean) / std\n",
    "\n",
    "print(f\"Input Shape: {X_tr.shape}\")\n",
    "\n",
    "# --- ã“ã“ã‹ã‚‰PyTorchã®ä¸–ç•Œ ---\n",
    "\n",
    "# NumPyé…åˆ—ã‚’ PyTorchã®ã€Œãƒ†ãƒ³ã‚½ãƒ«(Tensor)ã€ã«å¤‰æ›\n",
    "# Tensorã¨ã¯ã€ŒGPUã«ä¹—ã›ã‚‹ã“ã¨ãŒã§ãã‚‹NumPyé…åˆ—ã€ã®ã“ã¨ã ã¨æ€ãˆã°ã„ã„\n",
    "# .float() ã§ 32bitæµ®å‹•å°æ•°ç‚¹æ•°ã«ã™ã‚‹ (ã“ã‚ŒãŒAIã®æ¨™æº–)\n",
    "X_tr_tensor = torch.from_numpy(X_tr).float()\n",
    "y_tr_tensor = torch.from_numpy(y_tr).float()\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ãƒ¢ãƒ‡ãƒ«å®šç¾© (Simple MLP)\n",
    "# ---------------------------------------------------------\n",
    "# nn.Module ã‚’ç¶™æ‰¿ã—ã¦ã€Œã“ã‚Œã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§ã™ã€ã¨å®£è¨€\n",
    "class PureMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PureMLP, self).__init__()  # è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–ï¼ˆãŠã¾ã˜ãªã„ï¼‰\n",
    "\n",
    "        # nn.Sequential: éƒ¨å“ã‚’é †ç•ªã«ãƒ‘ãƒƒã‚¯è©°ã‚ã™ã‚‹ç®±\n",
    "        self.net = nn.Sequential(\n",
    "            # 1å±¤ç›®: å…¨çµåˆå±¤ (y = xW + b)\n",
    "            # NumPyã§æ›¸ã„ãŸ `np.dot(x, W) + b` ã‚’è‡ªå‹•ã§ã‚„ã‚‹éƒ¨å“\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # æ´»æ€§åŒ–é–¢æ•°: ReLU\n",
    "            # NumPyã§æ›¸ã„ãŸ `mask = (x<=0); out[mask]=0` ã‚’è‡ªå‹•ã§ã‚„ã‚‹éƒ¨å“\n",
    "            nn.ReLU(),\n",
    "            # 2å±¤ç›®: å‡ºåŠ›å±¤\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "        # é‡ã¿ã®åˆæœŸåŒ– (Heã®åˆæœŸå€¤)\n",
    "        # NumPyã§æ›¸ã„ãŸ `randn * sqrt(2/n)` ã‚’ã“ã“ã§ã‚„ã£ã¦ã„ã‚‹\n",
    "        # net[0] ã¯1å±¤ç›®ã®Linear, net[2] ã¯2å±¤ç›®ã®Linear\n",
    "        nn.init.kaiming_normal_(self.net[0].weight, nonlinearity=\"relu\")\n",
    "        nn.init.zeros_(self.net[0].bias)  # ãƒã‚¤ã‚¢ã‚¹ã¯0åˆæœŸåŒ–\n",
    "        nn.init.kaiming_normal_(self.net[2].weight, nonlinearity=\"linear\")\n",
    "        nn.init.zeros_(self.net[2].bias)\n",
    "\n",
    "    # é †ä¼æ’­ (Forward)\n",
    "    def forward(self, x):\n",
    "        # å…¥åŠ›xã‚’ãƒ‘ãƒƒã‚¯è©°ã‚ã—ãŸç®±ã«é€šã™ã ã‘\n",
    "        # layer1 -> ReLU -> layer2 ã¨ãƒ‡ãƒ¼ã‚¿ãŒæµã‚Œã‚‹\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# --- 1ã¤ã®Seedã§å­¦ç¿’ã™ã‚‹é–¢æ•° ---\n",
    "def train_one_seed(seed):\n",
    "    # PyTorchã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®š (å†ç¾æ€§ã®ãŸã‚)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # --- DataLoader (ãƒ‡ãƒ¼ã‚¿ä¾›çµ¦ä¿‚) ---\n",
    "    # å…¥åŠ›(X)ã¨æ­£è§£(y)ã‚’ã‚»ãƒƒãƒˆã«ã™ã‚‹\n",
    "    train_ds = TensorDataset(X_tr_tensor, y_tr_tensor)\n",
    "\n",
    "    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šå‡ºã—ã€ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦ä¾›çµ¦ã™ã‚‹å‡„è…•\n",
    "    # NumPyç‰ˆã§æ›¸ã„ãŸ `np.random.permutation` ã¨ `slice` ã®å‡¦ç†ã‚’å…¨éƒ¨ã‚„ã£ã¦ãã‚Œã‚‹\n",
    "    batch_size = 1024\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®å®Ÿä½“åŒ– & GPUã¸ã®è»¢é€ (.to(device))\n",
    "    model = PureMLP(X_tr.shape[1], 512).to(device)\n",
    "\n",
    "    # æå¤±é–¢æ•°: MSE (å¹³å‡äºŒä¹—èª¤å·®)\n",
    "    # NumPyç‰ˆã® `mean((y-t)^2)`\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: SGD (ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•)\n",
    "    # NumPyç‰ˆã® `MomentumSGD` ã‚¯ãƒ©ã‚¹ã¨åŒã˜åƒã\n",
    "    # model.parameters() ã§ã€W1, b1, W2, b2 ã‚’å…¨éƒ¨è‡ªå‹•ã§æ¸¡ã—ã¦ã„ã‚‹\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    epochs = 50\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    print(f\"ğŸš€ Seed {seed} Start...\")\n",
    "\n",
    "    # ã‚¨ãƒãƒƒã‚¯ã®ãƒ«ãƒ¼ãƒ—\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # ã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€ã«ã‚¹ã‚¤ãƒƒãƒ (Dropoutãªã©ãŒæœ‰åŠ¹ã«ãªã‚‹)\n",
    "\n",
    "        # ãƒŸãƒ‹ãƒãƒƒãƒã”ã¨ã®ãƒ«ãƒ¼ãƒ— (DataLoaderã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã™)\n",
    "        for inputs, targets in train_loader:\n",
    "            # ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«é€ã‚‹ (ã“ã‚Œå¿˜ã‚Œã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # --- 1. å‹¾é…ã®ãƒªã‚»ãƒƒãƒˆ ---\n",
    "            # â˜…è¶…é‡è¦: PyTorchã¯å‹¾é…ã‚’ã€Œè¶³ã—ç®—ã€ã—ã¦ã„ãä»•æ§˜ãªã®ã§ã€\n",
    "            # æ¯å› 0 ã«æˆ»ã•ãªã„ã¨ã€å‰ã®ãƒãƒƒãƒã®å‹¾é…ãŒæ®‹ã£ã¦ã—ã¾ã†ï¼\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # --- 2. æ¨è«– (Forward) ---\n",
    "            # NumPyç‰ˆã® `model.forward(x)`\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # --- 3. èª¤å·®è¨ˆç®— ---\n",
    "            # NumPyç‰ˆã® `criterion.forward(y, t)`\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # --- 4. é€†ä¼æ’­ (Backward) ---\n",
    "            # â˜…é­”æ³•ã®ã‚³ãƒãƒ³ãƒ‰â˜…\n",
    "            # ã“ã‚Œä¸€ç™ºã§ã€å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(W, b)ã®å¾®åˆ†(å‹¾é…)ã‚’è¨ˆç®—ã—ã€\n",
    "            # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã® `.grad` ã«æ ¼ç´ã™ã‚‹ã€‚\n",
    "            # NumPyç‰ˆã§æ‰‹æ›¸ãã—ãŸ `backward` é€£é–ã‚’å…¨éƒ¨è‡ªå‹•ã§ã‚„ã‚‹ã€‚\n",
    "            loss.backward()\n",
    "\n",
    "            # --- 5. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° ---\n",
    "            # NumPyç‰ˆã® `optimizer.step()`\n",
    "            # è¨ˆç®—ã•ã‚ŒãŸå‹¾é…ã‚’ä½¿ã£ã¦ã€W = W - lr * grad ã‚’å®Ÿè¡Œ\n",
    "            optimizer.step()\n",
    "\n",
    "        # --- æ¤œè¨¼ (Validation) ---\n",
    "        model.eval()  # ã€Œè©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã€ã«ã‚¹ã‚¤ãƒƒãƒ (å­¦ç¿’ã—ãªã„)\n",
    "\n",
    "        # `with torch.no_grad():`\n",
    "        # ã€Œã“ã“ã‹ã‚‰å…ˆã¯å‹¾é…è¨ˆç®—ã—ãªãã¦ã„ã„ã‚ˆã€ã¨ã„ã†å‘½ä»¤ã€‚\n",
    "        # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã¨é«˜é€ŸåŒ–ã®ãŸã‚ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã¯å¿…é ˆã€‚\n",
    "        with torch.no_grad():\n",
    "            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«é€ã£ã¦æ¨è«–\n",
    "            outputs_val = model(X_val_tensor.to(device))\n",
    "            # èª¤å·®è¨ˆç®—\n",
    "            val_loss = criterion(outputs_val, y_val_tensor.to(device)).item()\n",
    "\n",
    "        # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢æ›´æ–°æ™‚ã®ä¿å­˜å‡¦ç†\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿(state_dict)ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "            torch.save(model.state_dict(), f\"best_model_seed{seed}.pth\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"   Epoch {epoch+1} | Val: {val_loss:.4f}\")\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè¡Œ (ã“ã“ã¯ãƒ­ã‚¸ãƒƒã‚¯ã®ã¿)\n",
    "# ---------------------------------------------------------\n",
    "SEEDS = [42, 2026, 777]\n",
    "final_preds = np.zeros((len(X_test), 1))\n",
    "scores = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    # å­¦ç¿’å®Ÿè¡Œ\n",
    "    loss = train_one_seed(seed)\n",
    "    scores.append(loss)\n",
    "\n",
    "    # äºˆæ¸¬\n",
    "    # å­¦ç¿’æ™‚ã¨åŒã˜å½¢ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨æ„\n",
    "    model = PureMLP(X_tr.shape[1], 512).to(device)\n",
    "    # ä¿å­˜ã—ã¦ãŠã„ãŸãƒ™ã‚¹ãƒˆãªé‡ã¿ã‚’èª­ã¿è¾¼ã‚€\n",
    "    model.load_state_dict(torch.load(f\"best_model_seed{seed}.pth\"))\n",
    "    # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # GPUã§è¨ˆç®—ã—ã€çµæœã‚’CPU(.cpu())ã«æˆ»ã—ã¦ã€NumPyé…åˆ—(.numpy())ã«ã™ã‚‹\n",
    "        # æœ€å¾Œã«NumPyåŒå£«ã§è¶³ã—åˆã‚ã›ã‚‹\n",
    "        final_preds += model(X_test_tensor.to(device)).cpu().numpy()\n",
    "\n",
    "# å¹³å‡ã‚’ã¨ã‚‹ (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)\n",
    "final_preds /= len(SEEDS)\n",
    "avg_score = np.mean(scores)\n",
    "\n",
    "print(f\"\\nğŸ† Final Average Val Loss: {avg_score:.4f}\")\n",
    "\n",
    "# CSVä¿å­˜\n",
    "sample_sub[\"lever\"] = final_preds\n",
    "sample_sub.to_csv(\"submission_pytorch_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f5410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Reloading Data from CSV...\n",
      "Input Shape: (178959, 264)\n",
      "âœ… MomentumSGD Class has been updated.\n",
      "ğŸš€ Seed 42 Start (Pure NumPy)...\n",
      "   Epoch 10 | Val: 1.2261\n",
      "   Epoch 20 | Val: 1.1987\n",
      "   Epoch 30 | Val: 1.1961\n",
      "   Epoch 40 | Val: 1.1985\n",
      "   Epoch 50 | Val: 1.2058\n",
      "ğŸš€ Seed 2026 Start (Pure NumPy)...\n",
      "   Epoch 10 | Val: 1.2337\n",
      "   Epoch 20 | Val: 1.2283\n",
      "   Epoch 30 | Val: 1.1933\n",
      "   Epoch 40 | Val: 1.1907\n",
      "   Epoch 50 | Val: 1.1833\n",
      "ğŸš€ Seed 777 Start (Pure NumPy)...\n",
      "   Epoch 10 | Val: 1.2186\n",
      "   Epoch 20 | Val: 1.2000\n",
      "   Epoch 30 | Val: 1.1972\n",
      "   Epoch 40 | Val: 1.1874\n",
      "   Epoch 50 | Val: 1.1878\n",
      "\n",
      "ğŸ† Final Average Val Loss (NumPy): 1.1808\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ğŸ› ï¸ Operation \"Rosetta Stone\" - Pure NumPy Replica\n",
    "# =========================================================\n",
    "\n",
    "# æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª NumPy ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ã“ã‚ŒãŒå…¨ã¦ã®åŸºç¤)\n",
    "import numpy as np\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿æ“ä½œç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª Pandas ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ (PyTorchç‰ˆã¨å…¨ãåŒã˜å‡¦ç†)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ğŸ”„ Reloading Data from CSV...\")\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹æŒ‡å®š\n",
    "train_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/train.csv\"\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹æŒ‡å®š\n",
    "test_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/test.csv\"\n",
    "# æå‡ºç”¨ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‘ã‚¹æŒ‡å®š\n",
    "sub_path = \"../AI-Olympic_Mari_Study_Log/joai-competition-2026/sample_submission.csv\"\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã«ã™ã‚‹\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sub_path)\n",
    "\n",
    "\n",
    "# ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹é–¢æ•° (éå»ã®æ™‚é–“ã‚’æ¨ªã«ä¸¦ã¹ã‚‹)\n",
    "def add_lag_features(df, lag_counts=5):\n",
    "    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ (ç ´å£Šçš„å¤‰æ›´ã‚’é˜²ã)\n",
    "    df_lagged = df.copy()\n",
    "    # ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ã‚ãªã„ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆ\n",
    "    exclude_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "    # è„³æ´»å‹•ã®ã‚«ãƒ©ãƒ åã ã‘ã‚’æŠ½å‡º\n",
    "    brain_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "    # æŒ‡å®šã•ã‚ŒãŸå›æ•°(5å›)åˆ†ãƒ«ãƒ¼ãƒ—ã—ã¦éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "    for i in range(1, lag_counts + 1):\n",
    "        # iãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ãšã‚‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ\n",
    "        shifted = df[brain_cols].shift(i)\n",
    "        # ã‚«ãƒ©ãƒ åã« _lag1, _lag2 ãªã©ã‚’ã¤ã‘ã‚‹\n",
    "        shifted.columns = [f\"{c}_lag{i}\" for c in brain_cols]\n",
    "        # æ¨ªæ–¹å‘ã«é€£çµã™ã‚‹\n",
    "        df_lagged = pd.concat([df_lagged, shifted], axis=1)\n",
    "\n",
    "    # ãšã‚‰ã—ãŸã“ã¨ã§ç™ºç”Ÿã—ãŸæ¬ æå€¤(NaN)ã‚’0ã§åŸ‹ã‚ã‚‹\n",
    "    return df_lagged.fillna(0)\n",
    "\n",
    "\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "train_df = add_lag_features(train_df, lag_counts=5)\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã‚‚åŒã˜å‡¦ç†ã‚’è¡Œã†\n",
    "test_df = add_lag_features(test_df, lag_counts=5)\n",
    "\n",
    "# --- ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰² (Leakageé˜²æ­¢) ---\n",
    "# ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚µãƒ³ãƒ—ãƒ«ID(è©¦è¡ŒID)ã‚’å–å¾—\n",
    "unique_ids = train_df[\"sample_id\"].unique()\n",
    "# ä¹±æ•°ã®ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š (å†ç¾æ€§ç¢ºä¿)\n",
    "np.random.seed(42)\n",
    "# IDã®ãƒªã‚¹ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹\n",
    "shuffled_ids = np.random.permutation(unique_ids)\n",
    "# å…¨ä½“ã®80%ã®ä½ç½®ã‚’è¨ˆç®—\n",
    "split_point = int(len(shuffled_ids) * 0.8)\n",
    "# å‰åŠ80%ã‚’å­¦ç¿’ç”¨IDã¨ã™ã‚‹\n",
    "train_ids = shuffled_ids[:split_point]\n",
    "# å¾ŒåŠ20%ã‚’æ¤œè¨¼ç”¨IDã¨ã™ã‚‹\n",
    "val_ids = shuffled_ids[split_point:]\n",
    "\n",
    "# IDãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦DataFrameã‚’è¡Œå˜ä½ã§æŠ½å‡º (å­¦ç¿’ç”¨)\n",
    "tr_df = train_df[train_df[\"sample_id\"].isin(train_ids)]\n",
    "# IDãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦DataFrameã‚’è¡Œå˜ä½ã§æŠ½å‡º (æ¤œè¨¼ç”¨)\n",
    "val_df = train_df[train_df[\"sample_id\"].isin(val_ids)]\n",
    "\n",
    "# --- æ­£è¦åŒ–ã¨NumPyé…åˆ—åŒ– ---\n",
    "# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿(å­¦ç¿’ã«ä½¿ã‚ãªã„åˆ—)ã®ãƒªã‚¹ãƒˆ\n",
    "metadata_cols = [\"id\", \"sample_id\", \"mouse_id\", \"day_n\", \"time\", \"lever\"]\n",
    "# ç›®çš„å¤‰æ•°(äºˆæ¸¬ã—ãŸã„åˆ—)\n",
    "target_col = \"lever\"\n",
    "# å®Ÿéš›ã«å­¦ç¿’ã«ä½¿ã†ç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "feature_cols = [\n",
    "    c\n",
    "    for c in train_df.columns\n",
    "    if c not in metadata_cols and c != target_col and \"Unnamed\" not in c\n",
    "]\n",
    "\n",
    "# å­¦ç¿’ç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿(X)ã‚’NumPyé…åˆ—ã¨ã—ã¦å–å¾—\n",
    "X_tr_raw = tr_df[feature_cols].values\n",
    "# å­¦ç¿’ç”¨ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿(y)ã‚’NumPyé…åˆ—ã¨ã—ã¦å–å¾— (-1, 1)ã§ç¸¦ãƒ™ã‚¯ãƒˆãƒ«ã«ã™ã‚‹\n",
    "y_tr = tr_df[target_col].values.reshape(-1, 1)\n",
    "# æ¤œè¨¼ç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿(X)ã‚’å–å¾—\n",
    "X_val_raw = val_df[feature_cols].values\n",
    "# æ¤œè¨¼ç”¨ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿(y)ã‚’å–å¾—\n",
    "y_val = val_df[target_col].values.reshape(-1, 1)\n",
    "# æœ¬ç•ªãƒ†ã‚¹ãƒˆç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿(X)ã‚’å–å¾—\n",
    "X_test_raw = test_df[feature_cols].values\n",
    "\n",
    "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã‚’è¨ˆç®— (å„åˆ—ã”ã¨)\n",
    "mean = X_tr_raw.mean(axis=0)\n",
    "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åå·®ã‚’è¨ˆç®— (0é™¤ç®—é˜²æ­¢ã®ãŸã‚ã«å¾®å°å€¤ã‚’è¶³ã™)\n",
    "std = X_tr_raw.std(axis=0) + 1e-8\n",
    "\n",
    "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–: (x - å¹³å‡) / æ¨™æº–åå·®\n",
    "X_tr = (X_tr_raw - mean) / std\n",
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚‚ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŸºæº–ã€ã§æ­£è¦åŒ–\n",
    "X_val = (X_val_raw - mean) / std\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚‚ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŸºæº–ã€ã§æ­£è¦åŒ–\n",
    "X_test = (X_test_raw - mean) / std\n",
    "\n",
    "print(f\"Input Shape: {X_tr.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. éƒ¨å“å®šç¾© (PyTorchã®ä¸­èº«ã‚’æ‰‹ä½œã‚Šã™ã‚‹)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "# å…¨çµåˆå±¤ (nn.Linear ã«ç›¸å½“)\n",
    "class Linear:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # Heã®åˆæœŸå€¤ (Kaiming Init) ã§é‡ã¿Wã‚’åˆæœŸåŒ–\n",
    "        # ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ(randn) * sqrt(2/å…¥åŠ›æ•°)\n",
    "        self.W = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "        # ãƒã‚¤ã‚¢ã‚¹bã¯0ã§åˆæœŸåŒ–\n",
    "        self.b = np.zeros(hidden_size)\n",
    "        # é€†ä¼æ’­ã®ãŸã‚ã«å…¥åŠ›xã‚’ä¿å­˜ã—ã¦ãŠãå¤‰æ•°\n",
    "        self.x = None\n",
    "        # é‡ã¿ã®å‹¾é…ã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°\n",
    "        self.dW = None\n",
    "        # ãƒã‚¤ã‚¢ã‚¹ã®å‹¾é…ã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # é€†ä¼æ’­ã§ä½¿ã†ã®ã§ä»Šã®å…¥åŠ›ã‚’ä¿å­˜\n",
    "        self.x = x\n",
    "        # ç·šå½¢å¤‰æ›: y = xW + b (è¡Œåˆ—ç© + ãƒã‚¤ã‚¢ã‚¹)\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # å…¥åŠ›xã®å‹¾é… dx = dout * W^T\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        # é‡ã¿Wã®å‹¾é… dW = x^T * dout\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        # ãƒã‚¤ã‚¢ã‚¹bã®å‹¾é… db = doutã®åˆ—ã”ã¨ã®ç·å’Œ\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx\n",
    "\n",
    "\n",
    "# ReLUé–¢æ•° (nn.ReLU ã«ç›¸å½“)\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        # 0ä»¥ä¸‹ã ã£ãŸå ´æ‰€ã‚’è¦šãˆã¦ãŠããƒã‚¹ã‚¯\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 0ä»¥ä¸‹ã®å ´æ‰€ã‚’Trueã«ã™ã‚‹ãƒã‚¹ã‚¯ã‚’ä½œæˆ\n",
    "        self.mask = x <= 0\n",
    "        # å…¥åŠ›xã‚’ã‚³ãƒ”ãƒ¼\n",
    "        out = x.copy()\n",
    "        # 0ä»¥ä¸‹ã®å ´æ‰€ã‚’å¼·åˆ¶çš„ã«0ã«ã™ã‚‹ (ReLUã®å®šç¾©)\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # ä¸Šæµã‹ã‚‰ã®å‹¾é…ã®ã‚³ãƒ”ãƒ¼\n",
    "        dout[self.mask] = 0  # Forwardæ™‚ã«0ä»¥ä¸‹ã ã£ãŸå ´æ‰€ã¯ã€å‹¾é…ã‚’é€šã•ãªã„(0ã«ã™ã‚‹)\n",
    "        dx = dout\n",
    "        return dx\n",
    "\n",
    "\n",
    "# å¹³å‡äºŒä¹—èª¤å·® (nn.MSELoss ã«ç›¸å½“)\n",
    "# â€» PyTorchã®MSELossã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ 0.5 ã‚’æ›ã‘ãªã„ \"mean((y-t)^2)\" ãªã®ã§ãã‚Œã«åˆã‚ã›ã‚‹\n",
    "class MSELoss:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        self.loss = None\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        # èª¤å·®ã®äºŒä¹—å¹³å‡ã‚’è¨ˆç®—\n",
    "        self.loss = np.mean((y - t) ** 2)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å–å¾—\n",
    "        batch_size = self.t.shape[0]\n",
    "        # MSEã®å¾®åˆ†: 2 * (y - t) / N\n",
    "        # PyTorchã®MSELossã«åˆã‚ã›ã‚‹ãŸã‚ã€ä¿‚æ•°2ã‚’ã¤ã‘ã‚‹ï¼\n",
    "        dx = (2.0 * (self.y - self.t) / batch_size) * dout\n",
    "        return dx\n",
    "\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«å…¨ä½“ (SimplePyTorchMLP ã‚¯ãƒ©ã‚¹ã«ç›¸å½“)\n",
    "class PureMLP_Model:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # å±¤ã‚’å®šç¾©\n",
    "        self.layer1 = Linear(input_size, hidden_size)  # 1å±¤ç›®\n",
    "        self.relu = ReLU()  # æ´»æ€§åŒ–\n",
    "        self.layer2 = Linear(hidden_size, 1)  # 2å±¤ç›®(å‡ºåŠ›)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚’é †ç•ªã«é€šã™\n",
    "        x = self.layer1.forward(x)\n",
    "        x = self.relu.forward(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # é€†é †ã«é€šã™ (Backpropagation)\n",
    "        dout = self.layer2.backward(dout)\n",
    "        dout = self.relu.backward(dout)\n",
    "        dout = self.layer1.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ› ï¸ Fix: MomentumSGD Class (Robust Ver.)\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "# æœ€é©åŒ–æ‰‹æ³• (ä¿®æ­£ç‰ˆ)\n",
    "class MomentumSGD:\n",
    "    def __init__(self, params, lr=0.001, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}\n",
    "        self.params = params\n",
    "\n",
    "        for key in params.keys():\n",
    "            # \"_grad\" ã§çµ‚ã‚ã‚‰ãªã„ã‚‚ã®ï¼ˆW1, b1ãªã©ï¼‰ã ã‘é€Ÿåº¦vã‚’ä½œã‚‹\n",
    "            if not key.endswith(\"_grad\"):\n",
    "                self.v[key] = np.zeros_like(params[key])\n",
    "\n",
    "    def step(self):\n",
    "        # è¾æ›¸ã®ã‚­ãƒ¼ã‚’ãƒªã‚¹ãƒˆåŒ–ã—ã¦ãƒ«ãƒ¼ãƒ—ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰\n",
    "        keys = list(self.params.keys())\n",
    "\n",
    "        for key in keys:\n",
    "            # â˜…ã“ã“ãŒé­”é™¤ã‘â˜…\n",
    "            # ã‚­ãƒ¼ãŒ \"_grad\" ã§çµ‚ã‚ã‚‹å ´åˆï¼ˆä¾‹: W1_gradï¼‰ã¯ã€\n",
    "            # ãã‚Œè‡ªä½“ãŒå‹¾é…ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€æ›´æ–°å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "            if key.endswith(\"_grad\"):\n",
    "                continue\n",
    "\n",
    "            # ã“ã“ã«æ¥ã‚‹ã®ã¯ \"W1\", \"b1\" ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿\n",
    "            param = self.params[key]\n",
    "\n",
    "            # å¯¾å¿œã™ã‚‹å‹¾é…ã‚’å–ã‚Šå‡ºã™ (W1 -> W1_grad)\n",
    "            grad_key = key + \"_grad\"\n",
    "            grad = self.params[grad_key]\n",
    "\n",
    "            # ãƒ¢ãƒ¼ãƒ¡ãƒ³ã‚¿ãƒ ã®å¼: v = m*v - lr*grad\n",
    "            # å‚é“ã‚’è»¢ãŒã‚‹ãƒœãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€éå»ã®é€Ÿåº¦(v)ã‚’è¶³ã—åˆã‚ã›ã‚‹\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grad\n",
    "\n",
    "            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°: W = W + v\n",
    "            param += self.v[key]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ã“ã‚Œã§ã‚¯ãƒ©ã‚¹ã‚’å†å®šç¾©ã—ãŸã€‚\n",
    "# ã•ã‚ã€å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ã‚‚ã†ä¸€åº¦å›ã›ï¼\n",
    "# ---------------------------------------------------------\n",
    "print(\"âœ… MomentumSGD Class has been updated.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. å­¦ç¿’å®Ÿè¡Œé–¢æ•° (PyTorchã®train_modelã«ç›¸å½“)\n",
    "# ---------------------------------------------------------\n",
    "def train_one_seed(seed):\n",
    "    # å†ç¾æ€§ã®ãŸã‚ã®Seedå›ºå®š\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    batch_size = 1024\n",
    "    input_size = X_tr.shape[1]\n",
    "    hidden_size = 512\n",
    "    epochs = 50\n",
    "    lr = 0.001  # PyTorchç‰ˆã«åˆã‚ã›ã‚‹\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–\n",
    "    model = PureMLP_Model(input_size, hidden_size)\n",
    "\n",
    "    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®æº–å‚™ (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¾æ›¸ã«ã¾ã¨ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹)\n",
    "    params_dict = {\n",
    "        \"W1\": model.layer1.W,\n",
    "        \"b1\": model.layer1.b,\n",
    "        \"W2\": model.layer2.W,\n",
    "        \"b2\": model.layer2.b,\n",
    "        # å‹¾é…ã‚’å…¥ã‚Œã‚‹å ´æ‰€ã¯ã€ãƒ«ãƒ¼ãƒ—å†…ã§éƒ½åº¦æ›´æ–°ã•ã‚Œã‚‹ãŒã€å‚ç…§ã‚’æ¸¡ã™ãŸã‚ã«ä»®ç½®ã\n",
    "        \"W1_grad\": None,\n",
    "        \"b1_grad\": None,\n",
    "        \"W2_grad\": None,\n",
    "        \"b2_grad\": None,\n",
    "    }\n",
    "\n",
    "    optimizer = MomentumSGD(params_dict, lr=lr, momentum=0.9)\n",
    "    criterion = MSELoss()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    print(f\"ğŸš€ Seed {seed} Start (Pure NumPy)...\")\n",
    "\n",
    "    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "    train_size = X_tr.shape[0]\n",
    "    # 1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°\n",
    "    iter_per_epoch = int(max(train_size / batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ã‚·ãƒ£ãƒƒãƒ•ãƒ« (DataLoaderã®shuffle=Trueã«ç›¸å½“)\n",
    "        idx = np.random.permutation(train_size)\n",
    "\n",
    "        for i in range(iter_per_epoch):\n",
    "            # ãƒŸãƒ‹ãƒãƒƒãƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²ã‚’ä½œæˆ\n",
    "            batch_mask = idx[i * batch_size : (i + 1) * batch_size]\n",
    "            x_batch = X_tr[batch_mask]\n",
    "            t_batch = y_tr[batch_mask]\n",
    "\n",
    "            # --- Forward ---\n",
    "            y_pred = model.forward(x_batch)\n",
    "            loss = criterion.forward(y_pred, t_batch)\n",
    "\n",
    "            # --- Backward ---\n",
    "            # æå¤±ã®å‹¾é… (1ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ)\n",
    "            dout = criterion.backward(1)\n",
    "            # ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’é€†ä¼æ’­\n",
    "            model.backward(dout)\n",
    "\n",
    "            # --- Update ---\n",
    "            # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãŒå‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã€è¨ˆç®—ã•ã‚ŒãŸæœ€æ–°ã®å‹¾é…ã‚’è¾æ›¸ã«å…¥ã‚Œã‚‹\n",
    "            params_dict[\"W1_grad\"] = model.layer1.dW\n",
    "            params_dict[\"b1_grad\"] = model.layer1.db\n",
    "            params_dict[\"W2_grad\"] = model.layer2.dW\n",
    "            params_dict[\"b2_grad\"] = model.layer2.db\n",
    "\n",
    "            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°å®Ÿè¡Œ\n",
    "            optimizer.step()\n",
    "\n",
    "        # --- Validation (Epochçµ‚äº†å¾Œ) ---\n",
    "        y_val_pred = model.forward(X_val)\n",
    "        val_loss = criterion.forward(y_val_pred, y_val)\n",
    "\n",
    "        # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢æ›´æ–°\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜ (è¾æ›¸ã®ã‚³ãƒ”ãƒ¼ã‚’ã¨ã‚‹)\n",
    "            best_params = {\n",
    "                \"W1\": model.layer1.W.copy(),\n",
    "                \"b1\": model.layer1.b.copy(),\n",
    "                \"W2\": model.layer2.W.copy(),\n",
    "                \"b2\": model.layer2.b.copy(),\n",
    "            }\n",
    "\n",
    "        # ãƒ­ã‚°å‡ºåŠ› (10ã‚¨ãƒãƒƒã‚¯ã”ã¨)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"   Epoch {epoch+1} | Val: {val_loss:.4f}\")\n",
    "\n",
    "    # å­¦ç¿’çµ‚äº†å¾Œã€ãƒ™ã‚¹ãƒˆãªé‡ã¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«æˆ»ã™ (ãƒ­ãƒ¼ãƒ‰)\n",
    "    model.layer1.W = best_params[\"W1\"]\n",
    "    model.layer1.b = best_params[\"b1\"]\n",
    "    model.layer2.W = best_params[\"W2\"]\n",
    "    model.layer2.b = best_params[\"b2\"]\n",
    "\n",
    "    return best_val_loss, model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè¡Œ\n",
    "# ---------------------------------------------------------\n",
    "SEEDS = [42, 2026, 777]\n",
    "final_preds = np.zeros((len(X_test), 1))\n",
    "scores = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    # å­¦ç¿’å®Ÿè¡Œ\n",
    "    loss, best_model = train_one_seed(seed)\n",
    "    scores.append(loss)\n",
    "\n",
    "    # äºˆæ¸¬ (ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
    "    test_pred = best_model.forward(X_test)\n",
    "    final_preds += test_pred\n",
    "\n",
    "# å¹³å‡ã‚’ã¨ã‚‹\n",
    "final_preds /= len(SEEDS)\n",
    "avg_score = np.mean(scores)\n",
    "\n",
    "print(f\"\\nğŸ† Final Average Val Loss (NumPy): {avg_score:.4f}\")\n",
    "\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "sample_sub[\"lever\"] = final_preds\n",
    "sample_sub.to_csv(\"submission_numpy_rosetta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7771bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start...\n",
      "Iter 0, Loss: 11.0077\n",
      "Iter 100, Loss: 0.0137\n",
      "Iter 200, Loss: 0.0043\n",
      "Iter 300, Loss: 0.0026\n",
      "Iter 400, Loss: 0.0018\n",
      "Iter 500, Loss: 0.0013\n",
      "Iter 600, Loss: 0.0011\n",
      "Iter 700, Loss: 0.0009\n",
      "Iter 800, Loss: 0.0007\n",
      "Iter 900, Loss: 0.0006\n",
      "\n",
      "Training Finished.\n",
      "Final Loss: 0.0005\n",
      "Input: [[0.5 0.5]]\n",
      "True Answer: 5.0\n",
      "Prediction:  4.9996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================================================================\n",
    "# 1. éƒ¨å“ã®å®šç¾© (ã“ã“ãŒã€ã‚¼ãƒ­ã‹ã‚‰DLã€ã®å¿ƒè‡“éƒ¨)\n",
    "# =========================================================================\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    \"\"\"\n",
    "    å…¨çµåˆå±¤ (Fully Connected Layer)\n",
    "    æœ¬ã§ã¯ 'Affine' ãƒ¬ã‚¤ãƒ¤ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹ã€‚\n",
    "    æ•°å¼: Y = Xãƒ»W + b\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, weight_init_std=0.01):\n",
    "        # é‡ã¿(W)ã¨ãƒã‚¤ã‚¢ã‚¹(b)ã®åˆæœŸåŒ–\n",
    "        # Heã®åˆæœŸå€¤ãªã©ã¯ä½¿ã‚ãšã€ã‚·ãƒ³ãƒ—ãƒ«ã«ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã§åˆæœŸåŒ–\n",
    "        self.W = weight_init_std * np.random.randn(input_size, output_size)\n",
    "        self.b = np.zeros(output_size)\n",
    "\n",
    "        # é€†ä¼æ’­ã®ãŸã‚ã«ã€å…¥åŠ›(x)ã¨å‹¾é…(dW, db)ã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"é †ä¼æ’­: å…¥åŠ›xã‚’å—ã‘å–ã‚Šã€æ¬¡ã¸æ¸¡ã™å€¤outã‚’è¨ˆç®—\"\"\"\n",
    "        self.x = x\n",
    "        # ã€é‡è¦ã€‘ è¡Œåˆ—ã®ç© (Dot Product)\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"é€†ä¼æ’­: ä¸Šæµã‹ã‚‰ã®å‹¾é…(dout)ã‚’å—ã‘å–ã‚Šã€ä¸‹æµã¸æµã™å‹¾é…(dx)ã‚’è¨ˆç®—\"\"\"\n",
    "        # 1. é‡ã¿Wã®å‹¾é… (å…¥åŠ›xã‚’è»¢ç½®ã—ã¦æ›ã‘ã‚‹)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "\n",
    "        # 2. ãƒã‚¤ã‚¢ã‚¹bã®å‹¾é… (åˆ—æ–¹å‘ã®ç·å’Œ)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "\n",
    "        # 3. å…¥åŠ›xã®å‹¾é… (é‡ã¿Wã‚’è»¢ç½®ã—ã¦æ›ã‘ã‚‹) -> å‰ã®å±¤ã¸æ¸¡ã™\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Relu:\n",
    "    \"\"\"\n",
    "    æ´»æ€§åŒ–é–¢æ•° (ReLU)\n",
    "    æ•°å¼: x > 0 ãªã‚‰ x, ãã‚Œä»¥å¤–ã¯ 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 0ä»¥ä¸‹ã®å ´æ‰€ã‚’Trueã«ã™ã‚‹ãƒã‚¹ã‚¯ã‚’ä½œæˆ\n",
    "        self.mask = x <= 0\n",
    "        out = x.copy()\n",
    "        # 0ä»¥ä¸‹ã®å€¤ã‚’0ã«ã™ã‚‹\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # é †ä¼æ’­ã§0ä»¥ä¸‹ã ã£ãŸå ´æ‰€ã¯ã€é€†ä¼æ’­ã§ã‚‚ä¿¡å·(å‹¾é…)ã‚’é€šã•ãªã„\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n",
    "\n",
    "\n",
    "class MSELoss:\n",
    "    \"\"\"\n",
    "    æå¤±é–¢æ•° (å¹³å‡äºŒä¹—èª¤å·®)\n",
    "    æ•°å¼: L = 1/2 * mean((y - t)^2)  â€»æœ¬ã«åˆã‚ã›1/2ã‚’ã¤ã‘ã‚‹ç‰ˆ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None  # äºˆæ¸¬å€¤\n",
    "        self.t = None  # æ­£è§£ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        # èª¤å·®ã‚’è¨ˆç®—\n",
    "        self.loss = 0.5 * np.mean((y - t) ** 2)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \"\"\"\n",
    "        ä¸€ç•ªæœ€å¾Œã®å±¤ãªã®ã§ã€ã“ã“ã‹ã‚‰é€†ä¼æ’­ãŒã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ã€‚\n",
    "        L = 1/2 * (y - t)^2 ã®å¾®åˆ†ã¯ (y - t)\n",
    "        \"\"\"\n",
    "        batch_size = self.t.shape[0]\n",
    "        # ãƒ‡ãƒ¼ã‚¿æ•°ã§å‰²ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã“ã¨\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    æœ€é©åŒ–æ‰‹æ³• (ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•)\n",
    "    æ•°å¼: W = W - lr * dW\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        # å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(W1, b1, W2, b2...)ã‚’æ›´æ–°\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ (éƒ¨å“ã‚’çµ„ã¿ç«‹ã¦ã‚‹)\n",
    "# =========================================================================\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # é‡ã¿ã®å…¥ã‚Œç‰©\n",
    "        self.params = {}\n",
    "\n",
    "        # å±¤ã®æº–å‚™\n",
    "        self.layers = {}\n",
    "\n",
    "        # --- 1å±¤ç›® (Affine1) ---\n",
    "        self.layers[\"Affine1\"] = Affine(input_size, hidden_size)\n",
    "        self.params[\"W1\"] = self.layers[\"Affine1\"].W\n",
    "        self.params[\"b1\"] = self.layers[\"Affine1\"].b\n",
    "\n",
    "        # --- æ´»æ€§åŒ– (ReLU) ---\n",
    "        self.layers[\"Relu1\"] = Relu()\n",
    "\n",
    "        # --- 2å±¤ç›® (Affine2) ---\n",
    "        self.layers[\"Affine2\"] = Affine(hidden_size, output_size)\n",
    "        self.params[\"W2\"] = self.layers[\"Affine2\"].W\n",
    "        self.params[\"b2\"] = self.layers[\"Affine2\"].b\n",
    "\n",
    "        # --- æœ€å¾Œã®å±¤ (Loss) ---\n",
    "        self.last_layer = MSELoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        # ç™»éŒ²ã•ã‚ŒãŸå±¤ã‚’é †ç•ªã«é€šã™ã ã‘\n",
    "        for layer_name in [\"Affine1\", \"Relu1\", \"Affine2\"]:\n",
    "            x = self.layers[layer_name].forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # 1. é †ä¼æ’­ã§Lossã‚’è¨ˆç®— (å†…éƒ¨ã§å„å±¤ã«xãŒä¿å­˜ã•ã‚Œã‚‹)\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 2. é€†ä¼æ’­ (Backpropagation) ã‚¹ã‚¿ãƒ¼ãƒˆï¼\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)  # Losså±¤ã‹ã‚‰é€†æµé–‹å§‹\n",
    "\n",
    "        # å±¤ã‚’é€†é †ã«ã™ã‚‹ (Affine2 -> Relu1 -> Affine1)\n",
    "        layers = [\"Affine2\", \"Relu1\", \"Affine1\"]\n",
    "\n",
    "        for layer_name in layers:\n",
    "            dout = self.layers[layer_name].backward(dout)\n",
    "\n",
    "        # è¨ˆç®—ã•ã‚ŒãŸå‹¾é…ã‚’é›†ã‚ã‚‹\n",
    "        grads = {}\n",
    "        grads[\"W1\"] = self.layers[\"Affine1\"].dW\n",
    "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"W2\"] = self.layers[\"Affine2\"].dW\n",
    "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# 3. å®Ÿè¡Œï¼ (ãƒ‡ãƒ¼ã‚¿ã‚’æµã—è¾¼ã‚€)\n",
    "# =========================================================================\n",
    "\n",
    "# --- ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ ---\n",
    "# x: å…¥åŠ› (ä¾‹: æ°—æ¸©, æ¹¿åº¦) -> 2æ¬¡å…ƒ\n",
    "# t: æ­£è§£ (ä¾‹: ã‚¢ã‚¤ã‚¹ã®å£²ä¸Š) -> 1æ¬¡å…ƒ\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)  # 100å€‹ã®ãƒ‡ãƒ¼ã‚¿ã€å…¥åŠ›2æ¬¡å…ƒ\n",
    "T = 3 * X[:, 0] + 5 * X[:, 1] + 1  # æ­£è§£ãƒ«ãƒ¼ãƒ«: 3x1 + 5x2 + 1 (ç·šå½¢å›å¸°)\n",
    "T = T.reshape(-1, 1)  # å½¢ã‚’æ•´ãˆã‚‹ (100, 1)\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---\n",
    "input_size = 2\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "model = TwoLayerNet(input_size, hidden_size, output_size)\n",
    "optimizer = SGD(lr=0.1)\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "print(\"Training Start...\")\n",
    "for i in range(1000):  # 1000å›å­¦ç¿’\n",
    "    # 1. å‹¾é…ã‚’è¨ˆç®— (èª¤å·®é€†ä¼æ’­æ³•ï¼)\n",
    "    grads = model.gradient(X, T)\n",
    "\n",
    "    # 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° (SGDï¼)\n",
    "    optimizer.update(model.params, grads)\n",
    "\n",
    "    # ãƒ­ã‚°è¨˜éŒ²\n",
    "    loss = model.loss(X, T)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iter {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "# --- çµæœç¢ºèª ---\n",
    "print(\"\\nTraining Finished.\")\n",
    "print(f\"Final Loss: {loss:.4f}\")\n",
    "\n",
    "# äºˆæ¸¬ã—ã¦ã¿ã‚‹\n",
    "x_test = np.array([[0.5, 0.5]])  # å…¥åŠ›ãŒãã‚Œãã‚Œ0.5ã®ã¨ã\n",
    "t_true = 3 * 0.5 + 5 * 0.5 + 1  # æ­£è§£ã¯ 1.5 + 2.5 + 1 = 5.0\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(f\"Input: {x_test}\")\n",
    "print(f\"True Answer: {t_true}\")\n",
    "print(f\"Prediction:  {y_pred[0][0]:.4f}\")\n",
    "\n",
    "# å­¦ç¿’æ›²ç·šã®è¡¨ç¤º\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss Curve (Zero to DL Style)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
